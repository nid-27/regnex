{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Agent Financial Analysis System\n",
        "Converted automatically to Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and building knowledge bases...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> No vector db provided                                                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[33mWARNING \u001b[0m No vector db provided                                                                                     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  âœ“ queued: Sentences_50Agree.txt\n",
            "Queued 1 text file(s) into finance_kb\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">INFO</span> Loading knowledge base                                                                                        \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[34mINFO\u001b[0m Loading knowledge base                                                                                        \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> No vector db provided                                                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[33mWARNING \u001b[0m No vector db provided                                                                                     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ queued 2 CSV file(s)\n",
            "âœ“ Knowledge bases loaded and indexed (build() not needed in Agno 1.5.9)\n",
            "Agents created.\n"
          ]
        }
      ],
      "source": [
        "\"\"\" \n",
        "Multi-Agent Financial Analysis System (Rewritten)\n",
        "- Ensures agents only use provided knowledge bases (text files & CSVs)\n",
        "- Forces retrieval, builds KBs, and prevents hallucinations by passing retrieved\n",
        "  content as strict context to agents.\n",
        "\n",
        "Instructions:\n",
        "1. Place your .txt files in `financeAgent/data/` and .csv files in `csvAgent/data/`.\n",
        "2. Run this notebook/script. It will load, build, and index the KBs.\n",
        "3. Use the `ask_team(query)` helper which retrieves relevant documents first,\n",
        "   then calls the agents with ONLY that retrieved context.\n",
        "\n",
        "Make changes easily: search, chunk, or retrieval parameters are at the top as constants.\n",
        "\"\"\"\n",
        "\n",
        "# Standard library\n",
        "import os\n",
        "import glob\n",
        "import pathlib\n",
        "import json\n",
        "import traceback\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Third-party\n",
        "import pandas as pd\n",
        "\n",
        "# ====== AGNO imports ======\n",
        "from agno.knowledge.text import TextKnowledgeBase\n",
        "from agno.knowledge.csv import CSVKnowledgeBase\n",
        "from agno.agent import Agent\n",
        "from agno.models.google import Gemini\n",
        "\n",
        "# ---------------------- CONFIG ----------------------\n",
        "FINANCE_DIR = pathlib.Path(\"financeAgent/data\")\n",
        "CSV_DIR = pathlib.Path(\"csvAgent/data\")\n",
        "\n",
        "TOP_K_TEXT = 6\n",
        "CSV_TOP_K = 100\n",
        "\n",
        "FINANCE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "CSV_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def safe_read_text(file_path: str) -> str:\n",
        "    encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']\n",
        "    for enc in encodings:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding=enc) as f:\n",
        "                return f.read()\n",
        "        except UnicodeDecodeError:\n",
        "            continue\n",
        "    raise UnicodeDecodeError(f\"Could not decode {file_path}\")\n",
        "\n",
        "print(\"Loading and building knowledge bases...\")\n",
        "\n",
        "finance_kb = TextKnowledgeBase(\n",
        "    name=\"finance_kb\",\n",
        "    description=\"Financial documents (news, reports, notes)\",\n",
        "    path=str(FINANCE_DIR),\n",
        ")\n",
        "\n",
        "loaded_finance = 0\n",
        "for file_path in glob.glob(str(FINANCE_DIR / \"*.txt\")):\n",
        "    try:\n",
        "        _ = safe_read_text(file_path)\n",
        "        finance_kb.load_documents([file_path])\n",
        "        loaded_finance += 1\n",
        "        print(f\"  âœ“ queued: {os.path.basename(file_path)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  âœ— failed to queue {file_path}: {e}\")\n",
        "\n",
        "print(f\"Queued {loaded_finance} text file(s) into finance_kb\")\n",
        "\n",
        "csv_kb = CSVKnowledgeBase(\n",
        "    name=\"csv_kb\",\n",
        "    description=\"CSV financial time series & metrics\",\n",
        "    path=str(CSV_DIR),\n",
        ")\n",
        "\n",
        "csv_files = glob.glob(str(CSV_DIR / \"*.csv\"))\n",
        "if csv_files:\n",
        "    try:\n",
        "        csv_kb.load_documents(csv_files)\n",
        "        print(f\"âœ“ queued {len(csv_files)} CSV file(s)\")\n",
        "    except Exception as e:\n",
        "        print(f\"âœ— failed to queue CSV files: {e}\")\n",
        "else:\n",
        "    print(\"No CSV files found; CSV KB empty.\")\n",
        "\n",
        "print(\"âœ“ Knowledge bases loaded and indexed (build() not needed in Agno 1.5.9)\")\n",
        "\n",
        "model = Gemini(id=\"gemini-2.5-flash\")\n",
        "\n",
        "FINANCE_INSTRUCTIONS = [\n",
        "    \"STRICT RAG MODE: You MUST only answer using the provided documents passed in the context.\",\n",
        "    \"Do not use any world knowledge beyond the content explicitly provided to you.\",\n",
        "    \"If the information is not present in the provided context, reply exactly: 'Not enough information in the provided documents.'\",\n",
        "    \"When you use a fact from a document, include a short citation line like: [source: <filename>, start=<index>].\",\n",
        "]\n",
        "\n",
        "CSV_INSTRUCTIONS = [\n",
        "    \"STRICT RAG MODE: Use ONLY the CSV rows / columns provided in the context.\",\n",
        "    \"If a requested date/column/value is missing, reply: 'Data not available in files.'\",\n",
        "    \"When summarizing numbers, include the source CSV filename and row indices if possible.\",\n",
        "]\n",
        "\n",
        "LEADER_INSTRUCTIONS = [\n",
        "    \"You are the Team Leader. Your role is to decompose complex queries into specialized sub-queries.\",\n",
        "    \"STEP 1 - ANALYZE: Break down the user query into components that require different expertise:\",\n",
        "    \"  - Identify what data/dates are needed (CSV Agent responsibility)\",\n",
        "    \"  - Identify what sentiment/analysis/concepts are needed (Finance Agent responsibility)\",\n",
        "    \"STEP 2 - DECOMPOSE: Create specialized sub-queries for each agent:\",\n",
        "    \"  - For CSV Agent: Ask specifically for data, dates, prices, volumes, metrics\",\n",
        "    \"  - For Finance Agent: Ask specifically for sentiment, concepts, analysis, opinions related to the topic\",\n",
        "    \"STEP 3 - DELEGATE: Send tailored sub-queries to each agent\",\n",
        "    \"STEP 4 - COLLATE: Combine responses from both agents to answer the original query:\",\n",
        "    \"  - Show data from CSV Agent\",\n",
        "    \"  - Show sentiment/analysis from Finance Agent\",\n",
        "    \"  - Connect them to provide a complete answer\",\n",
        "    \"  - Present in a clear, structured format\",\n",
        "]\n",
        "\n",
        "finance_agent = Agent(\n",
        "    name=\"Finance_Document_Expert\",\n",
        "    role=\"Financial Document Specialist\",\n",
        "    model=model,\n",
        "    knowledge=finance_kb,\n",
        "    add_context=True,\n",
        "    instructions=FINANCE_INSTRUCTIONS,\n",
        "    markdown=True,\n",
        "    show_tool_calls=True,\n",
        ")\n",
        "\n",
        "csv_agent = Agent(\n",
        "    name=\"CSV_Data_Analyst\",\n",
        "    role=\"CSV Financial Data Analyst\",\n",
        "    model=model,\n",
        "    knowledge=csv_kb,\n",
        "    add_context=True,\n",
        "    instructions=CSV_INSTRUCTIONS,\n",
        "    markdown=True,\n",
        "    show_tool_calls=True,\n",
        ")\n",
        "\n",
        "team_leader = Agent(\n",
        "    name=\"Team_Leader\",\n",
        "    role=\"Multi-Agent Coordinator and Team Leader\",\n",
        "    model=model,\n",
        "    team=[finance_agent, csv_agent],\n",
        "    instructions=LEADER_INSTRUCTIONS,\n",
        "    markdown=True,\n",
        "    show_tool_calls=True,\n",
        ")\n",
        "\n",
        "print(\"Agents created.\")\n",
        "\n",
        "def retrieve_finance_docs(query: str, top_k: int = TOP_K_TEXT):\n",
        "    try:\n",
        "        return finance_kb.search(query, top_k=top_k)\n",
        "    except:\n",
        "        return finance_kb.search(query)\n",
        "\n",
        "def retrieve_csv_rows(query: str, top_k: int = CSV_TOP_K):\n",
        "    matches = {}\n",
        "    import re\n",
        "    date_like = None\n",
        "    m = re.search(r\"(\\d{4}[-/]\\d{2}[-/]\\d{2})\", query)\n",
        "    if m:\n",
        "        date_like = m.group(1)\n",
        "\n",
        "    for csv_file in glob.glob(str(CSV_DIR / \"*.csv\")):\n",
        "        try:\n",
        "            df = pd.read_csv(csv_file)\n",
        "        except:\n",
        "            df = pd.read_csv(csv_file, engine='python', on_bad_lines='skip')\n",
        "\n",
        "        matched = pd.DataFrame()\n",
        "        if date_like:\n",
        "            for col in df.columns:\n",
        "                try:\n",
        "                    parsed = pd.to_datetime(df[col], errors='coerce')\n",
        "                    mask = parsed.astype(str).str.contains(date_like)\n",
        "                    if mask.any():\n",
        "                        matched = df[mask]\n",
        "                        break\n",
        "                except:\n",
        "                    pass\n",
        "        else:\n",
        "            kw = query.lower()\n",
        "            masks = []\n",
        "            for col in df.columns:\n",
        "                if df[col].dtype == object:\n",
        "                    masks.append(df[col].str.lower().str.contains(kw, na=False))\n",
        "            if masks:\n",
        "                combined = masks[0]\n",
        "                for m in masks[1:]:\n",
        "                    combined = combined | m\n",
        "                matched = df[combined]\n",
        "\n",
        "        if not matched.empty:\n",
        "            matches[os.path.basename(csv_file)] = matched.head(top_k)\n",
        "\n",
        "    return matches\n",
        "\n",
        "def build_finance_context(docs):\n",
        "    parts = []\n",
        "    for i, d in enumerate(docs):\n",
        "        txt = getattr(d, 'text', '')\n",
        "        src = d.metadata.get('source', f'doc_{i}')\n",
        "        snippet = txt[:800].replace(\"\\n\", \" \")\n",
        "        parts.append(f\"[source: {src}] {snippet}\")\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "def build_csv_context(matches):\n",
        "    parts = []\n",
        "    for fname, df in matches.items():\n",
        "        preview = df.head(10).to_csv(index=False)\n",
        "        parts.append(f\"[CSV: {fname}]\\nColumns: {', '.join(df.columns)}\\nPreview:\\n{preview}\")\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "def ask_team(query: str) -> str:\n",
        "    \"\"\"\n",
        "    Main function that decomposes a complex query into sub-queries for specialized agents.\n",
        "    Each agent gets a tailored query based on their expertise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # STEP 1: Team Leader analyzes and decomposes the query\n",
        "        decompose_prompt = f\"\"\"Analyze this query and decompose it into two specific sub-queries:\n",
        "        \n",
        "Original Query: {query}\n",
        "\n",
        "Provide EXACTLY in this format:\n",
        "CSV_SUBQUERY: [specific query for CSV data - focus on Date,Open,High,Low,Close,Volume,OpenInt]\n",
        "FINANCE_SUBQUERY: [specific query for finance documents - focus on sentiment, analysis, concepts]\n",
        "\n",
        "Example:\n",
        "Original: \"For 2005-03-11 data, can you tell if agreed, neutral or negative\"\n",
        "CSV_SUBQUERY: \"What is the stock data for 2005-03-11? Show me the date, open, high, low, close, OpenInt and volume.\"\n",
        "FINANCE_SUBQUERY: \"What does the document say about agreed, neutral, or negative sentiment? What are the key sentiments or opinions expressed?\"\n",
        "\"\"\"\n",
        "        \n",
        "        decompose_res = team_leader.run(decompose_prompt)\n",
        "        decompose_txt = getattr(decompose_res, \"content\", str(decompose_res))\n",
        "        \n",
        "        # Parse the decomposed queries\n",
        "        csv_subquery = \"\"\n",
        "        finance_subquery = \"\"\n",
        "        \n",
        "        for line in decompose_txt.split('\\n'):\n",
        "            if line.startswith('CSV_SUBQUERY:'):\n",
        "                csv_subquery = line.replace('CSV_SUBQUERY:', '').strip()\n",
        "            elif line.startswith('FINANCE_SUBQUERY:'):\n",
        "                finance_subquery = line.replace('FINANCE_SUBQUERY:', '').strip()\n",
        "        \n",
        "        print(f\"\\nðŸ“Š CSV Sub-Query: {csv_subquery}\")\n",
        "        print(f\"ðŸ“„ Finance Sub-Query: {finance_subquery}\\n\")\n",
        "        \n",
        "        # STEP 2: Retrieve relevant data for each agent\n",
        "        finance_hits = retrieve_finance_docs(finance_subquery if finance_subquery else query)\n",
        "        csv_hits = retrieve_csv_rows(csv_subquery if csv_subquery else query)\n",
        "\n",
        "        if not finance_hits and not csv_hits:\n",
        "            return \"No information found in knowledge bases.\"\n",
        "\n",
        "        finance_context = build_finance_context(finance_hits)\n",
        "        csv_context = build_csv_context(csv_hits)\n",
        "\n",
        "        # STEP 3: Send tailored queries to each agent with their specific context\n",
        "        finance_prompt = (\n",
        "            \"Use ONLY the context provided.\\n\\nCONTEXT:\\n\" + finance_context + \"\\n\\nQUERY:\\n\" + (finance_subquery if finance_subquery else query)\n",
        "        )\n",
        "        csv_prompt = (\n",
        "            \"Use ONLY the context provided.\\n\\nCONTEXT:\\n\" + csv_context + \"\\n\\nQUERY:\\n\" + (csv_subquery if csv_subquery else query)\n",
        "        )\n",
        "\n",
        "        f_res = finance_agent.run(finance_prompt, context=finance_context)\n",
        "        c_res = csv_agent.run(csv_prompt, context=csv_context)\n",
        "\n",
        "        f_txt = getattr(f_res, \"content\", str(f_res))\n",
        "        c_txt = getattr(c_res, \"content\", str(c_res))\n",
        "\n",
        "        # STEP 4: Team Leader collates responses\n",
        "        collate_prompt = f\"\"\"You are the Team Leader. Collate the responses from both agents to answer the original query.\n",
        "\n",
        "Original Query: {query}\n",
        "\n",
        "CSV Agent Response:\n",
        "{c_txt}\n",
        "\n",
        "Finance Agent Response:\n",
        "{f_txt}\n",
        "\n",
        "Now synthesize these into a complete, coherent answer that combines both data and sentiment/analysis insights.\"\"\"\n",
        "\n",
        "        l_res = team_leader.run(collate_prompt)\n",
        "        l_txt = getattr(l_res, \"content\", str(l_res))\n",
        "\n",
        "        return json.dumps({\n",
        "            \"query\": query,\n",
        "            \"csv_subquery\": csv_subquery,\n",
        "            \"finance_subquery\": finance_subquery,\n",
        "            \"csv_agent_response\": c_txt,\n",
        "            \"finance_agent_response\": f_txt,\n",
        "            \"team_leader_final_answer\": l_txt,\n",
        "        }, indent=2)\n",
        "\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fe47ddb8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query: For 2005-03-11 to 2005-03-28 data, can you tell me if the Operating profit is positive, negative or neutral\n",
            "\n",
            "================================================================================\n",
            "\n",
            "\n",
            "ðŸ“Š CSV Sub-Query: Retrieve the Operating profit, date, open, high, low, close, OpenInt, and volume for the period 2005-03-11 to 2005-03-28.\n",
            "ðŸ“„ Finance Sub-Query: Based on financial analysis, determine if the Operating profit for 2005-03-11 to 2005-03-28 is positive, negative, or neutral.\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">WARNING </span> No vector db provided                                                                                     \n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[33mWARNING \u001b[0m No vector db provided                                                                                     \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Example 1: Basic query without CSV data\n",
        "query1 = \"For 2005-03-11 to 2005-03-28 data, can you tell me if the Operating profit is positive, negative or neutral\"\n",
        "\n",
        "\n",
        "\n",
        "print(\"Query:\", query1)\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "r = ask_team(query1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "15a9e41a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"query\": \"For 2005-03-11 to 2005-03-28 data, can you tell me if the Operating profit is positive, negative or neutral\",\n",
            "  \"csv_subquery\": \"Retrieve the Operating profit, date, open, high, low, close, OpenInt, and volume for the period 2005-03-11 to 2005-03-28.\",\n",
            "  \"finance_subquery\": \"Based on financial analysis, determine if the Operating profit for 2005-03-11 to 2005-03-28 is positive, negative, or neutral.\",\n",
            "  \"csv_agent_response\": \"Data not available in files for Operating profit.\\n\\nHere is the requested information from `aap.us.csv` for the period 2005-03-11 to 2005-03-28:\\n\\n**aap.us.csv (row 1):**\\nDate: 2005-03-11\\nOpen: 32.994\\nHigh: 33.447\\nLow: 32.964\\nClose: 33.388\\nVolume: 1235848\\nOpenInt: 0\",\n",
            "  \"finance_agent_response\": \"Not enough information in the provided documents.\",\n",
            "  \"team_leader_final_answer\": \"I understand you were looking for information regarding the operating profit for the period 2005-03-11 to 2005-03-28.\\n\\nUnfortunately, neither the CSV Agent nor the Finance Agent could provide the requested data on \\\"Operating profit.\\\"\\n\\n*   The **CSV Agent** explicitly stated that \\\"Data not available in files for Operating profit.\\\"\\n*   The **Finance Agent** also confirmed \\\"Not enough information in the provided documents\\\" to determine the operating profit.\\n\\nHowever, the CSV Agent did provide the following trading data for 2005-03-11 from the `aap.us.csv` file:\\n\\n**aap.us.csv (row 1):**\\n*   **Date:** 2005-03-11\\n*   **Open:** 32.994\\n*   **High:** 33.447\\n*   **Low:** 32.964\\n*   **Close:** 33.388\\n*   **Volume:** 1235848\\n*   **OpenInt:** 0\\n\\nIn summary, based on the available information, I cannot determine if the operating profit for the specified period was positive, negative, or neutral.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(r)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
